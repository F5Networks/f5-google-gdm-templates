image: ${ARTIFACTORY_SERVER}/dockerhub-remote/python:3.7-alpine

services:
  - ${ARTIFACTORY_SERVER}/dockerhub-remote/docker:dind

variables:
  GIT_SUBMODULE_STRATEGY: recursive

stages:
  - lint
  - smoke-tests
  - sprinkle-tests
  - droplets
  - release

# lint
lint_generator:
  stage: lint
  tags:
    - docker-executor
  except:
    refs:
      - schedules
      - triggers
      - pipelines
    variables:
      - $RELEASE_RUNTIME_INIT_TESTS == "true"
  script:
    - apk add --no-cache build-base
    - cd template-generator
    - pip install -r requirements.txt
    - make lint



# validate the template generator 'source' file(s) are always in sync with the
# generated content - i.e. running 'make all' after checking out a stable branch
# should never result in different generated content
run_generator_and_validate_no_diff:
  stage: smoke-tests
  tags:
    - docker-executor
  except:
    refs:
      - schedules
      - triggers
      - pipelines
    variables:
      - $RELEASE_RUNTIME_INIT_TESTS == "true"
  script:
    - apk add --no-cache build-base
    - apk add --no-cache git
    - apk add --no-cache jq
    - apk add --no-cache curl
    - curl https://dl.google.com/dl/cloudsdk/release/google-cloud-sdk.tar.gz > /tmp/google-cloud-sdk.tar.gz
    - mkdir -p /usr/local/gcloud && tar -C /usr/local/gcloud -xvf /tmp/google-cloud-sdk.tar.gz && /usr/local/gcloud/google-cloud-sdk/install.sh --quiet && rm /tmp/google-cloud-sdk.tar.gz
    - PATH="$PATH:/usr/local/gcloud/google-cloud-sdk/bin"
    - cd template-generator
    - pip install -r requirements.txt
    - python template_generator/main.py --gce
    - if git diff | grep 'diff --git'; then exit 1; else exit 0; fi

# run template generator smoke tests - validate file contents, etc.
run_smoke_tests:
  stage: smoke-tests
  tags:
    - docker-executor
  except:
    refs:
      - schedules
      - triggers
      - pipelines
    variables:
      - $RELEASE_RUNTIME_INIT_TESTS == "true"
  script:
    - apk add --no-cache build-base
    - apk add --no-cache bash
    - make run_smoke_tests

# validate README file(s) only contain links that respond with 200 OK
run_link_checker:
  image: ${ARTIFACTORY_SERVER}/dockerhub-remote/node:10
  stage: smoke-tests
  tags:
    - docker-executor
  only:
    refs:
      # the current intent is to run only on main and release branches
      - main
      - /^R.*/
  except:
    refs:
      - schedules
      - triggers
      - pipelines
    variables:
      - $RELEASE_RUNTIME_INIT_TESTS == "true"
  script:
    - make link_check
  allow_failure: true


pre_release_test_job:
  stage: sprinkle-tests
  tags:
    - docker-executor
  only:
    refs:
      - main
  except:
    variables:
      - $ANALYTICS_MESSAGE_PROCESS == "true"
      - $ANALYTICS_SCRIPTS_PROCESS == "true"
      - $VERIFY_REGKEY_COUNT == "true"
      - $REAPER_RUN == "true"
      - $DAILY_TESTS_MONITOR == "true"
      - $RELEASE_RUNTIME_INIT_TESTS == "true"
    refs:
      - schedules
      - triggers
      - pipelines
  variables:
    TEST_POLICY: automated-test-scripts/data/test_policies/pre_release_test.yaml
    STACK_TYPE: dewdrop-preproduction
  script:
    - pip install -r cloud-tools/master-job/requirements.txt
    - cloud-tools/master-job/sprinkler.py --test-plan $TEST_POLICY --token $CI_JOB_TOKEN --branch $CI_COMMIT_REF_NAME --stack-type $STACK_TYPE --project-id $CI_PROJECT_ID
  retry:
    max: 2
    when:
      - runner_system_failure
      - stuck_or_timeout_failure

post_release_test_job:
  stage: sprinkle-tests
  tags:
    - docker-executor
  only:
    - schedules
  except:
    variables:
      - $ANALYTICS_MESSAGE_PROCESS == "true"
      - $ANALYTICS_SCRIPTS_PROCESS == "true"
      - $VERIFY_REGKEY_COUNT == "true"
      - $REAPER_RUN == "true"
      - $DAILY_TESTS_MONITOR == "true"
      - $RELEASE_RUNTIME_INIT_TESTS == "true"
  variables:
    TEST_POLICY: cloud-tools/automated-test-scripts/data/test_policies/post_release_test.yaml
    STACK_TYPE: dewdrop-preproduction
  # Added a manual trigger for now so that this job doesn't get triggered after every commit
  when: manual
  script:
    - pip install -r cloud-tools/master-job/requirements.txt
    - cloud-tools/master-job/sprinkler.py --test-plan $TEST_POLICY --token $CI_JOB_TOKEN --branch $CI_COMMIT_REF_NAME --stack-type $STACK_TYPE --project-id $CI_PROJECT_ID
  retry:
    max: 2
    when:
      - runner_system_failure
      - stuck_or_timeout_failure

scheduled_test_job:
  stage: sprinkle-tests
  tags:
    - docker-executor
  only:
    - schedules
  variables:
    TEST_POLICY: set in schedule!
    STACK_TYPE: dewdrop-production
  script:
    - pip install -r cloud-tools/master-job/requirements.txt
    - cloud-tools/master-job/sprinkler.py --test-plan $TEST_POLICY --token $CI_JOB_TOKEN --branch $CI_COMMIT_REF_NAME --stack-type $STACK_TYPE --project-id $CI_PROJECT_ID
  retry:
    max: 2
    when:
      - runner_system_failure
      - stuck_or_timeout_failure


# This job gets triggered by the sprinkler.py script that get ran by the 'master_test_job' it ingests TEMPLATE_URL
# And TEMPLATE_PARAMETERS which are passed down by the sprinkler.py script. Using the variables runs dewdrop with
# the set environment variables
dewdrop_test_run:
  image: ${ARTIFACTORY_SERVER}/ecosystems-cloudsolutions-docker-dev/dewdrop:$DEWDROP_IMAGE_ID
  stage: droplets
  tags:
    - docker-executor
  variables:
    SSH_KEY: "$SSH_KEY"
    GOOGLE_PROJECT_ID: "$GOOGLE_PROJECT_ID"
    GOOGLE_PRIVATE_KEY_ID: "$GOOGLE_PRIVATE_KEY_ID"
    GOOGLE_CLIENT_EMAIL: "$GOOGLE_CLIENT_EMAIL"
    GOOGLE_CLIENT_ID: "$GOOGLE_CLIENT_ID"
    GOOGLE_PRIVATE_KEY: "$GOOGLE_PRIVATE_KEY"
    TEMPLATE_URL: "$TEMPLATE_URL"
    TEMPLATE_PARAMETERS: "$TEMPLATE_PARAMETERS"
    STACK_TYPE: "$STACK_TYPE"
    GITLAB_JOB_URL: "$CI_JOB_URL"
  only:
    variables:
      - $RUN_SCHEDULED_DEWDROP_TEST == "true"
  script:
    # the dewdrop image itself does not contain any test files, so ensure dewdrop
    # is run from the known location where test policies expect it to be
    # location: root of the cloud factory repository
    - python /dewdrop/dewdrop-docker.py

publish_to_github:
  image: ${ARTIFACTORY_SERVER}/dockerhub-remote/node:8
  stage: release
  only:
    - /(^publish-(v\d*[1-9]*\.)(\d*[1-9]*\.)(\d))/
  script:
    # install jq
    - apt-get update
    - apt-get install -y jq
    # Execute Release script to push source to github repo
    - ./cloud-tools/release-tool/publish_github.sh "$ALLOWED_DIRS" "$ALLOWED_FILES"
  variables:
    ALLOWED_DIRS: "experimental supported .github"
    ALLOWED_FILES: ".gitignore .gitattributes README.md google-bigip-version-matrix.md iapp-migration.md"
    GITLAB_API_URL: "$GOOGLE_URL"
    GIT_HUB_API_TOKEN: "$GOOGLE_GITHUB_API_TOKEN"
    GITLAB_PRIVATE_TOKEN: "$GOOGLE_GITLAB_API_TOKEN"
